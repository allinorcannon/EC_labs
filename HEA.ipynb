{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_regret_repair(path, D, costs, weights=0.5):\n",
    "    target_length = math.ceil(len(D) / 2)\n",
    "    path = list(path) + [path[0]]\n",
    "    edges = []\n",
    "    nodes_available = [x for x in range(len(D)) if x not in path]\n",
    "    for idx, node in enumerate(path):\n",
    "        if idx == len(path)-1: break\n",
    "        edges.append([node, path[(idx+1) % len(path)]])\n",
    "    while len(path) < target_length+1 and len(nodes_available) > 0:\n",
    "        M = np.zeros((len(nodes_available), len(edges)))\n",
    "        indices = np.array(nodes_available, dtype=int)\n",
    "        for edge_ix in range(len(edges)):\n",
    "            a, b = edges[edge_ix]\n",
    "            var = D[a, :] + D[:, b] - D[a, b] + costs\n",
    "            M[:,edge_ix] = var[indices]\n",
    "        best_score = -MAX_DIST\n",
    "        replaced_edge = 0\n",
    "        best_node = 0\n",
    "        for node_idx in range(len(nodes_available)):\n",
    "            best, second_best = np.partition(M[node_idx], 1)[:2]\n",
    "            regret = second_best - best\n",
    "            score = weights * regret - (1 - weights) * np.min(M[node_idx])\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                replaced_edge = np.argmin(M[node_idx])\n",
    "                best_node = nodes_available[node_idx]\n",
    "        path.insert(replaced_edge+1, best_node)\n",
    "        nodes_available.remove(best_node)\n",
    "        a, b = edges[replaced_edge]\n",
    "        edges.pop(replaced_edge)\n",
    "        edges.insert(replaced_edge, [a, best_node])\n",
    "        edges.insert(replaced_edge + 1, [best_node, b])\n",
    "    return path[:-1]\n",
    "\n",
    "def get_edges(path):\n",
    "    edges = []\n",
    "    for idx, node in enumerate(path):\n",
    "        edge = [node, path[(idx+1) % len(path)]]\n",
    "        edges.append(edge)\n",
    "    return edges\n",
    "\n",
    "def get_common_edges(path1, path2):\n",
    "    common_edges = []\n",
    "    for idx, edge_start in enumerate(path1):\n",
    "        edge_end = path1[(idx+1) % len(path1)]\n",
    "        if edge_start in path2:\n",
    "            e_idx = path2.index(edge_start)\n",
    "            if edge_end == path2[(e_idx+1) % len(path2)]:\n",
    "                edge = [edge_start, edge_end]\n",
    "                common_edges.append(edge)\n",
    "            elif edge_end == path2[(e_idx-1) % len(path2)]:\n",
    "                edge = [edge_start, edge_end]\n",
    "                common_edges.append(edge)\n",
    "    return common_edges\n",
    "\n",
    "\n",
    "def get_initial_edges_path(path1, path2):\n",
    "    offspring = []\n",
    "    edges = get_edges(path1)\n",
    "    common_edges = get_common_edges(path1, path2)\n",
    "    for edge in edges[1:]:\n",
    "        if edge in common_edges or edge[::-1] in common_edges:\n",
    "            if len(offspring) > 0:\n",
    "                if offspring[-1] != edge[0]:\n",
    "                    offspring.append(edge[0])\n",
    "                if offspring[0] != edge[1]:\n",
    "                    offspring.append(edge[1])\n",
    "            else:\n",
    "                offspring.extend(edge)\n",
    "    return offspring\n",
    "\n",
    "def combine_random(path1, path2, D):\n",
    "    common_nodes = [node for node in path1 if node in path2]\n",
    "    offspring = get_initial_edges_path(path1, path2)\n",
    "    nodes_available = [x for x in common_nodes if x not in offspring]\n",
    "    offspring.extend(nodes_available)\n",
    "    nodes_available = [x for x in range(len(D)) if x not in offspring]\n",
    "    while len(offspring) < len(path1):\n",
    "        node = random.choice(nodes_available)\n",
    "        offspring.append(node)\n",
    "        nodes_available.remove(node)\n",
    "    return offspring\n",
    "\n",
    "def combine_heuristic(path1, path2, D, costs):\n",
    "    offspring = get_initial_edges_path(path1, path2)\n",
    "    if len(offspring) == 0:\n",
    "        offspring.extend([path1[0], path1[1]])\n",
    "    repaired = greedy_regret_repair(offspring, D, costs)\n",
    "    return repaired\n",
    "\n",
    "# TODO change the implementation so that you can pass nodes available to regret repair\n",
    "\n",
    "def HEA(D, costs, LS_enable=False,  POP_SIZE = 20, time_limit=200):\n",
    "    counter = 0\n",
    "    population = []\n",
    "    scores = []\n",
    "    while len(population) < POP_SIZE:\n",
    "        path = random_sequence(D)\n",
    "        path = list(local_search(path, costs, D))\n",
    "        score = evaluate(D, path, costs)\n",
    "        if score not in scores:\n",
    "            population.append(list(path))\n",
    "            scores.append(score)\n",
    "    time_start = time.time()\n",
    "    while True:\n",
    "        counter += 1\n",
    "        parents = random.choices(population, k=2)\n",
    "        if random.random() < 0.5:\n",
    "            offspring = combine_random(parents[0], parents[1], D)\n",
    "            score = evaluate(D, offspring, costs)\n",
    "        else:\n",
    "            offspring = combine_heuristic(parents[0], parents[1], D, costs)\n",
    "            score = evaluate(D, offspring, costs)\n",
    "        if LS_enable:\n",
    "            offspring = list(local_search(offspring, costs, D))\n",
    "        offspring_score = evaluate(D, offspring, costs)\n",
    "        worst_idx = scores.index(max(scores))\n",
    "        if offspring_score < scores[worst_idx]:\n",
    "            if offspring not in population and offspring_score not in scores:\n",
    "                population[worst_idx] = offspring\n",
    "                scores[worst_idx] = offspring_score\n",
    "\n",
    "        if time.time() - time_start > time_limit:\n",
    "            break\n",
    "    best_found = population[scores.index(min(scores))]\n",
    "    return best_found, counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_solution(filename, D, costs, LS_enable=False,  POP_SIZE = 20, time_limit=200):\n",
    "    start = time.time()\n",
    "    path, counter = HEA(D, costs, LS_enable=False,  POP_SIZE=POP_SIZE, time_limit=time_limit)\n",
    "    end = time.time()\n",
    "    score = evaluate(D, path, costs)\n",
    "    return {\n",
    "        'Filename': filename,\n",
    "        'Version': 'LS' if LS_enable else 'no LS',\n",
    "        'Iterations': counter,\n",
    "        'Path': path,\n",
    "        'Score': score,\n",
    "        'Time': (end - start)\n",
    "    }\n",
    "\n",
    "# %%\n",
    "# result = evaluate_solution('TSPA.csv', D, costs)\n",
    "# result\n",
    "\n",
    "# %%\n",
    "if __name__ == \"__main__\":\n",
    "    test_start = time.time()\n",
    "    files = ['TSPA.csv', 'TSPB.csv', 'TSPC.csv', 'TSPD.csv']\n",
    "    for filename in files:\n",
    "        prefix = \"HEA\"\n",
    "        mapping_out_files= {\n",
    "            'TSPA.csv' : f'{prefix}_TSPA_out.csv',\n",
    "            'TSPB.csv' : f'{prefix}_TSPB_out.csv',\n",
    "            'TSPC.csv' : f'{prefix}_TSPC_out.csv',\n",
    "            'TSPD.csv' : f'{prefix}_TSPD_out.csv'\n",
    "        }\n",
    "        nodes, costs, D = read_data(filename)\n",
    "        num_iterations = 10\n",
    "        time_limit = 200\n",
    "        results = Parallel(n_jobs=-1)(delayed(evaluate_solution)(filename, D, costs, LS_enable=LS_enable, POP_SIZE=20, time_limit=time_limit)\n",
    "                                    for LS_enable in [True, False]\n",
    "                                    for i in range(num_iterations)\n",
    "                                    )\n",
    "\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.to_csv(mapping_out_files[filename])\n",
    "        test_end = time.time()\n",
    "        print(test_end - test_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
