{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "import copy\n",
    "\n",
    "# Changes:\n",
    "# 1. Start with population including greedy cycle and greedy regret results\n",
    "# 2. Change the random operator to common edges + common nodes + greedy cycle\n",
    "# 3. Add diversification mechanism - randomly perturb the solution with probability accoring to temperature\n",
    "\n",
    "# improvements:\n",
    "# - as an initial population, use some of the previous methods (e.g. greedy cycle, greedy regret) - they are fast and will give a good starting point, further improved LS.\n",
    "# change the operators, add new one\n",
    "# diversification machanism\n",
    "\n",
    "\n",
    "# combine random introduces too much randomness and it makes the method run LS for much too long\n",
    "\n",
    "# TODO add new recombination operator not introducing as much randomness\n",
    "# common edges, then make subpaths from common nodes and insert them randomly, then use greedy cycle to repair the solution\n",
    "\n",
    "# TODO Start initial population from greedy cycle, greedy regret, and the rest as before\n",
    "\n",
    "# TODO add diversification mechanism\n",
    "# randomly perturb the solution with probability accoring to temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75055\n",
      "74469\n",
      "74507\n",
      "74881\n",
      "75052\n",
      "74727\n",
      "74789\n",
      "74609\n",
      "75138\n",
      "75244\n",
      "74441\n",
      "74244\n",
      "73914\n",
      "76094\n",
      "74677\n",
      "75212\n",
      "74681\n",
      "75128\n",
      "74651\n",
      "74303\n",
      "74238\n",
      "74903\n",
      "74689\n",
      "73847\n",
      "74893\n",
      "74410\n",
      "74437\n",
      "73791\n",
      "74260\n",
      "74541\n",
      "74510\n",
      "74470\n",
      "74403\n",
      "74262\n",
      "74371\n",
      "74473\n",
      "73818\n",
      "73917\n",
      "73426\n",
      "73726\n",
      "73494\n",
      "74335\n",
      "73965\n",
      "73820\n",
      "74400\n",
      "73749\n",
      "74257\n",
      "73863\n",
      "73751\n",
      "74129\n",
      "74178\n",
      "73921\n",
      "73881\n",
      "73767\n",
      "73770\n",
      "73530\n",
      "73414\n",
      "73795\n",
      "73642\n",
      "73760\n",
      "73275\n",
      "73653\n",
      "73829\n",
      "73779\n",
      "73313\n",
      "73618\n",
      "73412\n",
      "73776\n",
      "73705\n",
      "73439\n",
      "73473\n",
      "73233\n",
      "73659\n",
      "73587\n",
      "73695\n",
      "73464\n",
      "73633\n",
      "73533\n",
      "73375\n",
      "73516\n",
      "73547\n",
      "73249\n",
      "73592\n",
      "73198\n",
      "73393\n",
      "73475\n",
      "73330\n",
      "73352\n",
      "73199\n",
      "73436\n",
      "73203\n",
      "73164\n",
      "73318\n",
      "73363\n",
      "73333\n",
      "73314\n",
      "73229\n",
      "73337\n",
      "73254\n",
      "73258\n",
      "73059\n",
      "73130\n",
      "Diversify\n",
      "73097\n",
      "73175\n",
      "Diversify\n",
      "73072\n",
      "Diversify\n",
      "73165\n",
      "73145\n",
      "73143\n",
      "73220\n",
      "73255\n",
      "73224\n",
      "Diversify\n",
      "73074\n",
      "73131\n",
      "73054\n",
      "Diversify\n",
      "Diversify\n",
      "73027\n",
      "73008\n",
      "73192\n",
      "73155\n",
      "73042\n",
      "73122\n",
      "73149\n",
      "Diversify\n",
      "Diversify\n",
      "73154\n",
      "Diversify\n",
      "73094\n",
      "Diversify\n",
      "73052\n",
      "Diversify\n",
      "73018\n",
      "Diversify\n",
      "73013\n",
      "Diversify\n",
      "73064\n",
      "73028\n",
      "73047\n",
      "Diversify\n",
      "Diversify\n",
      "73096\n",
      "Diversify\n",
      "Diversify\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([192,\n",
       "  199,\n",
       "  41,\n",
       "  177,\n",
       "  1,\n",
       "  75,\n",
       "  189,\n",
       "  109,\n",
       "  119,\n",
       "  130,\n",
       "  152,\n",
       "  11,\n",
       "  160,\n",
       "  106,\n",
       "  48,\n",
       "  92,\n",
       "  26,\n",
       "  8,\n",
       "  124,\n",
       "  80,\n",
       "  14,\n",
       "  111,\n",
       "  89,\n",
       "  12,\n",
       "  94,\n",
       "  98,\n",
       "  156,\n",
       "  172,\n",
       "  6,\n",
       "  66,\n",
       "  190,\n",
       "  72,\n",
       "  73,\n",
       "  31,\n",
       "  95,\n",
       "  169,\n",
       "  112,\n",
       "  51,\n",
       "  135,\n",
       "  99,\n",
       "  101,\n",
       "  167,\n",
       "  45,\n",
       "  186,\n",
       "  127,\n",
       "  88,\n",
       "  153,\n",
       "  161,\n",
       "  76,\n",
       "  145,\n",
       "  128,\n",
       "  132,\n",
       "  36,\n",
       "  55,\n",
       "  22,\n",
       "  117,\n",
       "  15,\n",
       "  108,\n",
       "  171,\n",
       "  21,\n",
       "  194,\n",
       "  79,\n",
       "  87,\n",
       "  141,\n",
       "  144,\n",
       "  154,\n",
       "  81,\n",
       "  180,\n",
       "  32,\n",
       "  62,\n",
       "  53,\n",
       "  195,\n",
       "  113,\n",
       "  74,\n",
       "  163,\n",
       "  61,\n",
       "  71,\n",
       "  20,\n",
       "  64,\n",
       "  185,\n",
       "  116,\n",
       "  27,\n",
       "  147,\n",
       "  96,\n",
       "  59,\n",
       "  143,\n",
       "  159,\n",
       "  164,\n",
       "  178,\n",
       "  19,\n",
       "  0,\n",
       "  149,\n",
       "  50,\n",
       "  91,\n",
       "  121,\n",
       "  43,\n",
       "  77,\n",
       "  4,\n",
       "  114,\n",
       "  175],\n",
       " 791)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def greedy_cycle(path, D, costs):\n",
    "    path = list(path)\n",
    "    target_length = math.ceil(len(D) / 2)\n",
    "    while len(path) < target_length:\n",
    "        closest_node = 0\n",
    "        best_increase = MAX_DIST\n",
    "        free_nodes = [x for x in range(D.shape[0]) if x not in path]\n",
    "        for idx in range(len(path)):\n",
    "            for new_node in free_nodes:\n",
    "                if idx == 0:\n",
    "                    prev_node = path[-1]\n",
    "                    next_node = path[0]\n",
    "                else:\n",
    "                    prev_node = path[idx - 1]\n",
    "                    next_node = path[idx]\n",
    "                curr_increase = (\n",
    "                    D[prev_node, new_node]\n",
    "                    + D[new_node, next_node]\n",
    "                    - D[prev_node, next_node]\n",
    "                    + costs[new_node]\n",
    "                )\n",
    "                if curr_increase < best_increase:\n",
    "                    best_increase = curr_increase\n",
    "                    closest_node = new_node\n",
    "                    node_pos = idx\n",
    "        path.insert(node_pos, closest_node)\n",
    "    return np.array(path)\n",
    "\n",
    "def greedy_regret_repair(path, nodes_available,  D, costs, weights=0.5):\n",
    "    target_length = math.ceil(len(D) / 2)\n",
    "    path = list(path) + [path[0]]\n",
    "    edges = []\n",
    "    nodes_available = [x for x in range(len(D)) if x not in path]\n",
    "    for idx, node in enumerate(path):\n",
    "        if idx == len(path)-1: break\n",
    "        edges.append([node, path[(idx+1) % len(path)]])\n",
    "    while len(path) < target_length+1 and len(nodes_available) > 0:\n",
    "        M = np.zeros((len(nodes_available), len(edges)))\n",
    "        indices = np.array(nodes_available, dtype=int)\n",
    "        for edge_ix in range(len(edges)):\n",
    "            a, b = edges[edge_ix]\n",
    "            var = D[a, :] + D[:, b] - D[a, b] + costs\n",
    "            M[:,edge_ix] = var[indices]\n",
    "        best_score = -MAX_DIST\n",
    "        replaced_edge = 0\n",
    "        best_node = 0\n",
    "        for node_idx in range(len(nodes_available)):\n",
    "            best, second_best = np.partition(M[node_idx], 1)[:2]\n",
    "            regret = second_best - best\n",
    "            score = weights * regret - (1 - weights) * np.min(M[node_idx])\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                replaced_edge = np.argmin(M[node_idx])\n",
    "                best_node = nodes_available[node_idx]\n",
    "        path.insert(replaced_edge+1, best_node)\n",
    "        nodes_available.remove(best_node)\n",
    "        a, b = edges[replaced_edge]\n",
    "        edges.pop(replaced_edge)\n",
    "        edges.insert(replaced_edge, [a, best_node])\n",
    "        edges.insert(replaced_edge + 1, [best_node, b])\n",
    "    return path[:-1]\n",
    "\n",
    "def get_edges(path):\n",
    "    edges = []\n",
    "    for idx, node in enumerate(path):\n",
    "        edge = [node, path[(idx+1) % len(path)]]\n",
    "        edges.append(edge)\n",
    "    return edges\n",
    "\n",
    "def get_common_edges(path1, path2):\n",
    "    common_edges = []\n",
    "    for idx, edge_start in enumerate(path1):\n",
    "        edge_end = path1[(idx+1) % len(path1)]\n",
    "        if edge_start in path2:\n",
    "            e_idx = path2.index(edge_start)\n",
    "            if edge_end == path2[(e_idx+1) % len(path2)]:\n",
    "                edge = [edge_start, edge_end]\n",
    "                common_edges.append(edge)\n",
    "            elif edge_end == path2[(e_idx-1) % len(path2)]:\n",
    "                edge = [edge_start, edge_end]\n",
    "                common_edges.append(edge)\n",
    "    return common_edges\n",
    "\n",
    "\n",
    "def get_initial_edges_path(path1, path2):\n",
    "    offspring = []\n",
    "    edges = get_edges(path1)\n",
    "    common_edges = get_common_edges(path1, path2)\n",
    "    for edge in edges[1:]:\n",
    "        if edge in common_edges or edge[::-1] in common_edges:\n",
    "            if len(offspring) > 0:\n",
    "                if offspring[-1] != edge[0]:\n",
    "                    offspring.append(edge[0])\n",
    "                if offspring[0] != edge[1]:\n",
    "                    offspring.append(edge[1])\n",
    "            else:\n",
    "                offspring.extend(edge)\n",
    "    return offspring\n",
    "\n",
    "def combine_new(path1, path2, D, costs):\n",
    "    common_nodes = [node for node in path1 if node in path2]\n",
    "    offspring = get_initial_edges_path(path1, path2)\n",
    "    nodes_available = [x for x in common_nodes if x not in offspring]\n",
    "    offspring.extend(nodes_available)\n",
    "    offspring = greedy_cycle(offspring, D, costs)\n",
    "    return offspring\n",
    "\n",
    "def combine_heuristic(path1, path2, D, costs):\n",
    "    offspring = get_initial_edges_path(path1, path2)\n",
    "    if len(offspring) == 0:\n",
    "        offspring.extend([path1[0], path1[1]])\n",
    "    common_nodes = [node for node in path1 if node in path2 and node not in offspring]\n",
    "    repaired = greedy_regret_repair(offspring, common_nodes, D, costs)\n",
    "    nodes_available = [x for x in range(len(D)) if x not in repaired]\n",
    "    repaired = greedy_regret_repair(repaired, nodes_available, D, costs)\n",
    "    return repaired\n",
    "\n",
    "def perturbation_swap5(D, cycle, n=10):\n",
    "    og_nodes = set(cycle)\n",
    "    nodes = set(list(range(D.shape[0])))\n",
    "    unused = nodes - og_nodes\n",
    "    copy_cycle = copy.deepcopy(cycle)\n",
    "    for i in range(n):\n",
    "        random_unused = random.choice(list(unused))\n",
    "        unused = unused - set([random_unused])\n",
    "        random_index = random.choice(list(range(len(cycle))))\n",
    "        copy_cycle[random_index] = random_unused\n",
    "    return copy_cycle\n",
    "\n",
    "def perturbation_replacenn(D, costs, path, n=10):\n",
    "    random_indices = random.sample(list(range(len(path))), n)\n",
    "    copy_cycle = copy.deepcopy(path)\n",
    "    for i in range(n):\n",
    "        next_index = (random_indices[i] + 1) % len(path)\n",
    "        distances = copy.deepcopy(D[copy_cycle[random_indices[i]], :]) + costs\n",
    "        distances[copy_cycle] = MAX_DIST\n",
    "        copy_cycle[next_index] = np.argmin(distances)\n",
    "    return copy_cycle\n",
    "\n",
    "def diversify(population, scores, D, costs):\n",
    "    # select 10 percent of population with worst scores from the population, perform a perturbation on them, and apply LS\n",
    "    # if the score is better than the worst score, replace it\n",
    "\n",
    "    # select 10 percent\n",
    "    # print('Diversify')\n",
    "    worst_idx = np.argsort(scores)[-int(len(population) * 0.2):]\n",
    "    worst = [population[idx] for idx in worst_idx]\n",
    "    worst_scores = [scores[idx] for idx in worst_idx]\n",
    "    for idx in range(len(worst)):\n",
    "        perturbed = perturbation_swap5(D, worst[idx])\n",
    "        perturbed = list(local_search(perturbed, costs, D))\n",
    "        perturbed_score = evaluate(D, perturbed, costs)\n",
    "        if perturbed_score < worst_scores[idx]:\n",
    "            population[worst_idx[idx]] = perturbed\n",
    "            scores[worst_idx[idx]] = perturbed_score\n",
    "    return population, scores\n",
    "\n",
    "\n",
    "def HEA(D, costs, LS_enable=False,  POP_SIZE = 20, time_limit=200):\n",
    "    counter = 0\n",
    "    population = []\n",
    "    scores = []\n",
    "    cycle = greedy_cycle(random_sequence(D), D, costs)\n",
    "    regret = greedy_regret_repair(list(cycle[:3]), [x for x in range(len(D)) if x not in cycle], D, costs)\n",
    "    population.append(list(regret))\n",
    "    population.append(list(cycle))\n",
    "    while len(population) < POP_SIZE:\n",
    "        path = random_sequence(D)\n",
    "        path = list(local_search(path, costs, D))\n",
    "        score = evaluate(D, path, costs)\n",
    "        if score not in scores:\n",
    "            population.append(list(path))\n",
    "            scores.append(score)\n",
    "    time_start = time.time()\n",
    "    c = 0\n",
    "    while True:\n",
    "        counter += 1\n",
    "        c += 1\n",
    "        parents = random.choices(population, k=2)\n",
    "        if random.random() < 0.5:\n",
    "            offspring = list(combine_new(parents[0], parents[1], D, costs))\n",
    "            score = evaluate(D, offspring, costs)\n",
    "        else:\n",
    "            offspring = combine_heuristic(parents[0], parents[1], D, costs)\n",
    "            score = evaluate(D, offspring, costs)\n",
    "        if LS_enable:\n",
    "            offspring = list(local_search(offspring, costs, D))\n",
    "        offspring_score = evaluate(D, offspring, costs)\n",
    "        worst_idx = scores.index(max(scores))\n",
    "        if c > 20:\n",
    "            population, scores = diversify(population, scores, D, costs)\n",
    "            c = 0\n",
    "        if offspring_score < scores[worst_idx]:\n",
    "            if offspring not in population and offspring_score not in scores:\n",
    "                c = 0\n",
    "                # print(offspring_score)\n",
    "                population[worst_idx] = offspring\n",
    "                scores[worst_idx] = offspring_score\n",
    "        if time.time() - time_start > time_limit:\n",
    "            break\n",
    "    best_found = population[scores.index(min(scores))]\n",
    "    return best_found, counter\n",
    "\n",
    "nodes, costs, D = read_data('TSPA.csv')\n",
    "HEA(D, costs, LS_enable=True,  POP_SIZE=20, time_limit=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/q7/rl6smtp16655qm4b40vyfj4m0000gn/T/ipykernel_59502/490649557.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mnum_iterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mtime_limit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         results = Parallel(n_jobs=-1)(delayed(evaluate_solution)(filename, D, costs, LS_enable=LS_enable, POP_SIZE=20, time_limit=time_limit)\n\u001b[0m\u001b[1;32m     35\u001b[0m                                     \u001b[0;32mfor\u001b[0m \u001b[0mLS_enable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                                     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    565\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def evaluate_solution(filename, D, costs, LS_enable=False,  POP_SIZE = 20, time_limit=200):\n",
    "    start = time.time()\n",
    "    path, counter = HEA(D, costs, LS_enable=False,  POP_SIZE=POP_SIZE, time_limit=time_limit)\n",
    "    end = time.time()\n",
    "    score = evaluate(D, path, costs)\n",
    "    return {\n",
    "        'Filename': filename,\n",
    "        'Version': 'LS' if LS_enable else 'no LS',\n",
    "        'Iterations': counter,\n",
    "        'Path': path,\n",
    "        'Score': score,\n",
    "        'Time': (end - start)\n",
    "    }\n",
    "\n",
    "# %%\n",
    "# result = evaluate_solution('TSPA.csv', D, costs)\n",
    "# result\n",
    "\n",
    "# %%\n",
    "if __name__ == \"__main__\":\n",
    "    test_start = time.time()\n",
    "    files = ['TSPA.csv', 'TSPB.csv', 'TSPC.csv', 'TSPD.csv']\n",
    "    for filename in files:\n",
    "        prefix = \"HEA\"\n",
    "        mapping_out_files= {\n",
    "            'TSPA.csv' : f'{prefix}_TSPA_out.csv',\n",
    "            'TSPB.csv' : f'{prefix}_TSPB_out.csv',\n",
    "            'TSPC.csv' : f'{prefix}_TSPC_out.csv',\n",
    "            'TSPD.csv' : f'{prefix}_TSPD_out.csv'\n",
    "        }\n",
    "        nodes, costs, D = read_data(filename)\n",
    "        num_iterations = 20\n",
    "        time_limit = 200\n",
    "        results = Parallel(n_jobs=-1)(delayed(evaluate_solution)(filename, D, costs, LS_enable=True, POP_SIZE=20, time_limit=time_limit)\n",
    "                                    for i in range(num_iterations)\n",
    "                                    )\n",
    "\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.to_csv(mapping_out_files[filename])\n",
    "        test_end = time.time()\n",
    "        print(test_end - test_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
